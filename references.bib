
@misc{schulman_proximal_2017,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1707.06347},
	doi = {10.48550/ARXIV.1707.06347},
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	urldate = {2024-10-08},
	publisher = {arXiv},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	year = {2017},
	note = {Version Number: 2},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@misc{schulman_proximal_2017-1,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	url = {http://arxiv.org/abs/1707.06347},
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	urldate = {2024-10-08},
	publisher = {arXiv},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	month = aug,
	year = {2017},
	note = {arXiv:1707.06347 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{schulman_proximal_2017-2,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1707.06347},
	doi = {10.48550/ARXIV.1707.06347},
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	urldate = {2024-10-08},
	publisher = {arXiv},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	year = {2017},
	note = {Version Number: 2},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@misc{schulman_proximal_2017-3,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	url = {http://arxiv.org/abs/1707.06347},
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	urldate = {2024-10-08},
	publisher = {arXiv},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	month = aug,
	year = {2017},
	note = {arXiv:1707.06347 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{schulman_proximal_2017-4,
	title = {Proximal {Policy} {Optimization} {Algorithms}},
	url = {https://arxiv.org/abs/1707.06347},
	doi = {https://doi.org/10.48550/arXiv.1707.06347},
	publisher = {arXiv},
	author = {schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	month = aug,
	year = {2017},
}

@techreport{noauthor_notitle_nodate,
}

@misc{noauthor_notitle_nodate-1,
}

@inproceedings{noauthor_notitle_nodate-2,
}

@misc{lin_tizero_2023,
	title = {{TiZero}: {Mastering} {Multi}-{Agent} {Football} with {Curriculum} {Learning} and {Self}-{Play}},
	shorttitle = {{TiZero}},
	url = {http://arxiv.org/abs/2302.07515},
	abstract = {Multi-agent football poses an unsolved challenge in AI research. Existing work has focused on tackling simplified scenarios of the game, or else leveraging expert demonstrations. In this paper, we develop a multi-agent system to play the full 11 vs. 11 game mode, without demonstrations. This game mode contains aspects that present major challenges to modern reinforcement learning algorithms; multi-agent coordination, long-term planning, and non-transitivity. To address these challenges, we present TiZero; a self-evolving, multi-agent system that learns from scratch. TiZero introduces several innovations, including adaptive curriculum learning, a novel self-play strategy, and an objective that optimizes the policies of multiple agents jointly. Experimentally, it outperforms previous systems by a large margin on the Google Research Football environment, increasing win rates by over 30\%. To demonstrate the generality of TiZero’s innovations, they are assessed on several environments beyond football; Overcooked, Multi-agent ParticleEnvironment, Tic-Tac-Toe and Connect-Four.},
	language = {en},
	urldate = {2024-10-07},
	publisher = {arXiv},
	author = {Lin, Fanqi and Huang, Shiyu and Pearce, Tim and Chen, Wenze and Tu, Wei-Wei},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07515 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@misc{noauthor_google-researchfootball_nodate,
	title = {google-research/football: {Check} out the new game server:},
	url = {https://github.com/google-research/football},
	urldate = {2024-10-07},
}

@misc{yu_surprising_2022,
	title = {The {Surprising} {Effectiveness} of {PPO} in {Cooperative}, {Multi}-{Agent} {Games}},
	url = {http://arxiv.org/abs/2103.01955},
	abstract = {Proximal Policy Optimization (PPO) is a ubiquitous on-policy reinforcement learning algorithm but is signiﬁcantly less utilized than off-policy learning algorithms in multi-agent settings. This is often due to the belief that PPO is signiﬁcantly less sample efﬁcient than off-policy methods in multi-agent systems. In this work, we carefully study the performance of PPO in cooperative multi-agent settings. We show that PPO-based multi-agent algorithms achieve surprisingly strong performance in four popular multi-agent testbeds: the particle-world environments, the StarCraft multi-agent challenge, Google Research Football, and the Hanabi challenge, with minimal hyperparameter tuning and without any domain-speciﬁc algorithmic modiﬁcations or architectures. Importantly, compared to competitive off-policy methods, PPO often achieves competitive or superior results in both ﬁnal returns and sample efﬁciency. Finally, through ablation studies, we analyze implementation and hyperparameter factors that are critical to PPO’s empirical performance, and give concrete practical suggestions regarding these factors. Our results show that when using these practices, simple PPO-based methods can be a strong baseline in cooperative multi-agent reinforcement learning. Source code is released at https://github.com/marlbenchmark/on-policy.},
	language = {en},
	urldate = {2024-10-07},
	publisher = {arXiv},
	author = {Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
	month = nov,
	year = {2022},
	note = {arXiv:2103.01955 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@book{yin_multi-agv_2024,
	title = {Multi-{AGV} {Path} {Planning} {Using} {Deep} {Reinforcement} {Learning} with {Internal} {Curiosity}},
	abstract = {Deep Reinforcement Learning (DRL) is promising for multi-agent path planning problems in which sparse external environmental rewards may cause the agent group to make overly conservative decisions and explore the environment inefficiently. In general, the reward shaping mechanism is used to mitigate the above problems with the additional reward function setting. However, it requires specific domain knowledge, which limits the general applicability, and the added reward functions are not necessarily applicable to all environments. This paper aims to improve the path planning efficiency of single agents and groups of agents with the Internal Curiosity Module (ICM) mechanism to boost the generalization abilities of the agents in different environments. To this end, we incorporate the internal curiosity mechanism into the soft actor-critic model for enhancing exploration strategies, adapting to environmental changes, and improving learning effectiveness. Then, we propose a multi-agent path planning method in which the curiosity mechanism is integrated with the Multi-Agent POsthumous Credit Assignment (MA-POCA) algorithm. The neural networks can automatically calculate the additional intrinsic rewards based on observed information about the environment and the actions taken by the group of agents. Based on our experiments, we make qualitative and quantitative analyses of the performance of the proposed methods and the baseline DRL methods. The experimental results show that our proposed methods can decline the number of learning episodes and the training time of path planning, so the proposed algorithms can accelerate the exploration of single agents or agent groups in the sparse reward environment.},
	author = {Yin, Huilin and Su, Shengkai and Lin, Yinjia and Festl, Karin and Yan, Jun and Watzenig, Daniel},
	month = jun,
	year = {2024},
	doi = {10.21203/rs.3.rs-4453111/v1},
}

@article{puneet_triton_nodate,
	title = {Triton {RCSC} 2023 {Team} {Description} {Paper}},
	language = {en},
	author = {Puneet, Yash and Gomes, Rafaella and Quach, Jenny and Kadekar, Rohil and Flar, Tyler and Islam, Syed and Singh, Rana and Wong, Jason and Nagatsuka, Kazuma and Shi, Steven and Parmar, Aditya and Alabiad, Ali and Soto-Ciriaco, Marisol and Yu, Yichen and Gutierrez, Francisco and Gomez, Joshua and Li, Peter and Mustahsin, Zarif and Kao, Nathan and Mehta, Pranav and Nickels, Kaylana and Martinez, Alejandro},
}

@misc{noauthor_small_nodate,
	title = {Small {Size} {League} {\textbar} {RoboCup} {Soccer} – {Information} for the administration of the {RoboCup} {Soccer} {Small} {Size} {League}},
	url = {https://ssl.robocup.org/},
	language = {en-US},
	urldate = {2024-10-03},
}

@misc{yu_surprising_2022-1,
	title = {The {Surprising} {Effectiveness} of {PPO} in {Cooperative}, {Multi}-{Agent} {Games}},
	url = {http://arxiv.org/abs/2103.01955},
	abstract = {Proximal Policy Optimization (PPO) is a ubiquitous on-policy reinforcement learning algorithm but is significantly less utilized than off-policy learning algorithms in multi-agent settings. This is often due to the belief that PPO is significantly less sample efficient than off-policy methods in multi-agent systems. In this work, we carefully study the performance of PPO in cooperative multi-agent settings. We show that PPO-based multi-agent algorithms achieve surprisingly strong performance in four popular multi-agent testbeds: the particle-world environments, the StarCraft multi-agent challenge, Google Research Football, and the Hanabi challenge, with minimal hyperparameter tuning and without any domain-specific algorithmic modifications or architectures. Importantly, compared to competitive off-policy methods, PPO often achieves competitive or superior results in both final returns and sample efficiency. Finally, through ablation studies, we analyze implementation and hyperparameter factors that are critical to PPO's empirical performance, and give concrete practical suggestions regarding these factors. Our results show that when using these practices, simple PPO-based methods can be a strong baseline in cooperative multi-agent reinforcement learning. Source code is released at {\textbackslash}url\{https://github.com/marlbenchmark/on-policy\}.},
	urldate = {2024-10-02},
	publisher = {arXiv},
	author = {Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
	month = nov,
	year = {2022},
	note = {arXiv:2103.01955 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@misc{noauthor_rules_2024,
	type = {Collaborative version control},
	title = {Rules of the {RoboCup} {Small} {Size} {League}},
	copyright = {Free to use, copy, and distribute; modifications prohibited.},
	url = {https://robocup-ssl.github.io/ssl-rules/sslrules.html},
	language = {English},
	urldate = {2024-09-19},
	journal = {Rules of the RoboCup Small Size League},
	month = may,
	year = {2024},
}

@incollection{da_silva_costa_multi-robot_2024,
	address = {Cham},
	title = {Multi-robot {Path} {Planning} with {Safety} {Based} {Control} {Applied} to the {Small} {Size} {League} {Robots}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-55014-0 978-3-031-55015-7},
	url = {https://link.springer.com/10.1007/978-3-031-55015-7_7},
	language = {en},
	urldate = {2024-09-17},
	booktitle = {Lecture {Notes} in {Computer} {Science}},
	publisher = {Springer Nature Switzerland},
	collaborator = {Da Silva Costa, Leonardo and Tonidandel, Flavio},
	year = {2024},
	doi = {10.1007/978-3-031-55015-7_7},
	note = {ISSN: 0302-9743, 1611-3349},
	pages = {78--89},
}

@article{kasaei_design_2010,
	title = {Design and {Implementation} {Solenoid} {Based} {Kicking} {Mechanism} for {Soccer} {Robot} {Applied} in {Robocup}-{MSL}},
	volume = {7},
	copyright = {http://journals.sagepub.com/page/policies/text-and-data-mining-license},
	issn = {1729-8814, 1729-8814},
	url = {http://journals.sagepub.com/doi/10.5772/10490},
	doi = {10.5772/10490},
	abstract = {RoboCup is an international competition to prompted robotics and related subject like: Artificial intelligence, Image processing, control, devise design and etc. One of the subjects in RoboCup competitions is Soccer. Naturally robotic soccer is an interactive and complex procedure. it might be so idealistic, but some consider a challenge with a real human football team in 2050, as the final goal of robotic soccer. There are several classes in robotic football matches such as: Middle size, Small size, simulation and so on. One of the most essential parts of a soccer robot in Middle size and Small size classes in the kicking system, this system is in charge of kicking the ball upon the command issued by the processor of robot. Almost every team develops their own unique shooting device. There are three main approaches to design and implement the robot kicking system. In this paper we designed and developed multi power kicking system that enables loop and vary shooting power. To design a good solenoid and to obtain maximum velocity of ball some parameters like: inductance, response time, resistance, force, dimensions and core-material should be balanced carefully. We used a DC-DC converter (Boost regulator) for getting different currents to have different power of shooting. We are going to review the advantages of all of those approaches. Next we are purposes a novel Solenoid-based kicking system which has already been successfully implemented in Adro RoboCup team.},
	language = {en},
	number = {4},
	urldate = {2024-09-16},
	journal = {International Journal of Advanced Robotic Systems},
	author = {Kasaei, S. Hamidreza Mohades and Kasaei, S. Mohammadreza Mohades and Kasaei, S. Alireza Mohades},
	month = dec,
	year = {2010},
	pages = {30},
}

@article{wu_compilation_nodate,
	title = {Compilation {Error} {Team} {Description} {Paper} for {Small} {Size} {League} of {Robocup} 2024},
	abstract = {Compilation errors have arisen from the robotics team participating in the Small-Size League (SSL) of robot soccer, affiliated with Ningbo University of Technology in Zhejiang Province, China. Our aspiration is to participate in the Robocup by 2024, and this article outlines the hardware specifications of our robot as well as the software advancements we have achieved. Our robot, meticulously crafted by our team, demonstrates a harmonious blend of mechanics and technology. Equally impressive is the software architecture of our robot, which integrates algorithms for path planning, ball prediction, decision-making, and more, resulting in an efficient and stable software framework. Our team has been diligently refining both the hardware and software components of our robot, aiming to make it competitive in the upcoming Robocup. Although there are numerous challenges ahead that we need to overcome and areas that require improvement, we are confident in our ability to create a robot that not only meets the competition standards but exceeds expectations.},
	language = {en},
	author = {Wu, Yuxuan and Liu, Kaiyang and Fan, Jiaming and Zhang, Hao and Minghe, Jiangyong Li and Li, Qinfeng and Li, Jun},
}

@article{bohm_er-force_nodate,
	title = {{ER}-{Force} 2024 {Extended} {Team} {Description} {Paper}},
	abstract = {This paper presents the proceedings of ER-Force, the RoboCup Small Size League team from Erlangen located at FriedrichAlexander-University Erlangen-Nürnberg, Germany. It describes the manufacturing process of our robot covers, as well as electronic simulations and measurements of our kicking assembly. Furthermore, it explains the statistical methods we use in our strategy to make it robust against noise in the vision data.},
	language = {en},
	author = {Böhm, Theodor and Gareis, Elisabeth and Hahn, Undine and Heineken, Tobias and Hopf, Valentin and Schmid, Michel and Schmidtmeier, Christoph and Wiedmann, Marco},
}

@article{sato_greentea_nodate,
	title = {{GreenTea} 2024 {Team} {Description} {Paper}},
	abstract = {GreenTea is a student organization founded in 2019. We will give an update on our robots since last year. In particular, we focus on our AI system, circuits, communication, and the local camera system installed on our robot itself. Also, we mention our contribution to the SSL community by conducting the video streaming of the RoboCup Japan Open. We look forward to seeing the robot in competition.},
	language = {en},
	author = {Sato, Hirotaka and Okamoto, Naoyuki and Ito, Akito and Kayaki, Shun and Nakao, Tomoki and Nishimura, Yuki and Hara, Yuto and Yuri, Rintaro},
}

@article{liang_icrs-fc_nodate,
	title = {{ICRS}-{FC} {Team} {Description} {Paper}},
	abstract = {This paper describes the efforts by ICRS FC to develop hardware and software capable of competing in the Robocup Small Size League. Since this is the first time ICRS FC has attempted to compete, the focus was on achieving a minimum viable robot, including movement, dribbling, kicking, and software systems that can be improved upon before the competition, and into future years.},
	language = {en},
	author = {Liang, Jingchuan and Smith, Ben and Huang, Fred},
}

@article{salehi_immortals_nodate,
	title = {Immortals 2024 {Extended} {Team} {Description} {Paper}},
	abstract = {This paper describes the recent work that has been done by the Immortals Robotics team for the upcoming RoboCup 2024 competition in Eindhoven, Netherlands.},
	language = {en},
	author = {Salehi, Ali and Shirazi, Mohammad Mahdi and Tabasi, Mohammad and Najafi, Omid and Nobaveh, Amoozandeh and Fazeli, MohammadHossein and Ghasemieh, MohammadAli and Niknezhad, MohammadReza and Talaeezadeh, Mustafa},
}

@article{goncalves_itandroids_nodate,
	title = {{ITAndroids} {Small} {Size} {League} {Team} {Description} {Paper} for {RoboCup} 2024},
	abstract = {ITAndroids is a robotics competition group associated with the Autonomous Computational Systems Lab (LAB-SCA) at the Aeronautics Institute of Technology (ITA). Our focus over the last year has primarily been on enhancing our software capabilities, with notable advancements in testing, logging, path planning, and in our GUI. Additionally, we have made substantial changes in electronics, particularly in the redesign of communication and movement boards. While mechanics saw more punctual improvements, notable progress has been made in the reconstruction of the kick mechanism and cover. Our efforts are geared towards establishing ourselves as a prominent Small Size League (SSL) team in both the Brazilian and global robotics scenarios. This paper outlines our recent developments, ongoing projects, and future aspirations.},
	language = {en},
	author = {Gonçalves, André and Freiberger, Andrei and Sousa, Arnon and Souza, Arthur and Silva, Artur and Yamamoto, Bruno and Morais, Emanoel and Filho, Felipe and Santos, João and Neves, Lucas and Barros, Lucas and Fusinato, Luiz and Alves, Luiz and Mendonça, Luís and Pedroso, Murilo and Farias, Nando and Façanha, Paulo and Barros, Valerio and Sousa, Yves},
}

@article{tanaka_kiks_nodate,
	title = {{KIKS} {Extended} {Team} {Description} for {RoboCup} 2024},
	abstract = {In this paper, we mainly describe the improvements and studies of the software system of SSL Team KIKS, which will participate in RoboCup 2024 Eindhoven. We will introduce the improvements of the educational board for new participants and the control results using IMU and current sensors. In addition, the eﬀectiveness of the robot’s self-position estimation was veriﬁed using rotary encoders and a Local Vision camera to support the Global Vision method. Furthermore, all matches of the Div-A knock-out stage of RoboCup 2023 were analyzed.},
	language = {en},
	author = {Tanaka, Ryuto and Miyajima, Daichi and Mitsuda, Hayato and Harada, Kazuaki and Nonoyama, Mizuki and Sato, Futa and Niimi, Haru and Miyauchi, Takahiro and Takanashi, Chihiro and Hachisuka, Yuzuki and Naito, Chiaki and Dori, Yota and Komatsu, Hirokazu and Sugiura, Toko},
}

@article{westermann_luhbots_nodate,
	title = {luhbots soccer {Extended} {Team} {Description} for {RoboCup} 2024},
	abstract = {This paper introduces a component of our offensive gameplay strategy which is designed for deployment in the Soccer Small Size League of the RoboCup. Emphasizing the positioning of offensive robots, a fundamental component of our attack strategy, we present three different approaches: Force Driven Positioning (FDP), Restricted Radial Positioning (RRP), and the Octopus Algorithm. These methods will be elucidated by providing an explanation of their function as well as a comparison of their respective advantages and disadvantages.},
	language = {en},
	author = {Westermann, Max and Pahl, Tobias and de Vries, Timo and Knackstedt, Sebastian and Seegemann, Larissa},
}

@article{bernet_namec_nodate,
	title = {{NAMeC} - {SSL} - {Team} {Description} {Paper} {Small} {Size} {League} {RoboCup} 2024 {Application} of {Qualification} in {Division} {B}},
	abstract = {This paper outlines the latest developments and enhancements undertaken by NAMeC, the RoboCup Small Size League team located in the University of Bordeaux, France.},
	language = {en},
	author = {Bernet, M and Bouvier, E and Calugi, A and Chew, B and Felix, P and Gautier, J and Godinat, C and Labbe, C and Lindois, J and Meunier, T W and Miqueu, E and Morera, N and Vlamynck, C A},
}

@article{thongsupan_orcabot_nodate,
	title = {{OrcaBOT} {Team} {Description} {Paper} 2024},
	abstract = {This paper describes the details of the proceeding SmallSized League robots from the second-generation OrcaBOT team. This year TDP, the team will prioritize the feasibility and stability of the robot, to improve and fix non-fulfillment from the first-generation team, from mechanical and electrical design that focuses on down-scaling the components to new communication and strategy in software.},
	language = {en},
	author = {Thongsupan, Tongthai and Sureechainirun, Ned and Yuvaniyama, Warit and Tantipjitkasem, Athit and Sripho, Piyamin and Sucharitjivavongse, Siriyakorn and Chetsawang, Julathit and Pruksorranan, Phisitphon and Sricharoenchit, Kaweewat and Sricharoendhum, Nuttaat and Anuntanasarn, Pramat and Limpornchitwilai, Pakorn and Penjinda, Nipparn and Suesakulchockchai, Natthaphak},
}

@article{franca_robocin_nodate,
	title = {{RobˆoCIn} {Small} {Size} {League} {Extended} {Team} {Description} {Paper} for {RoboCup} 2024},
	abstract = {RoboˆCIn has participated in RoboCup Small Size League since 2019, won its first world title in 2022 and second in 2023 (Division B), and is currently a four-time Latin-American champion. This paper presents our improvements to find a great first campaign at Division A in RoboCup 2024 in Eindhoven, Netherlands. During 2023, our team has successfully published 3 articles related to SSL at two high-impact conferences: the 26th RoboCup International Symposium and the 20th IEEE Latin American Robotics Symposium (LARS 2023). Over the past year, we have sought to improve our system and robots structurally, simplifying processes, improving performance, and providing more reliability. Furthermore, we’ll discuss the software improvements to increase the number of players as required in Division A.},
	language = {en},
	author = {Franca, Alberto and Barros, Beatriz and Gomes, Caue and Silva, Cecılia and Alves, Charles M and Barbosa, Davi C and Xavier, Driele and Araujo, Elisson and Pereira, Felipe and Cavalcanti, Lucas H and Asfora, Marcela and Alves, Matheus and Paixao, Matheus and Vasconcelos, Matheus and Vinıcius, Matheus and Melo, Joao G and Silva, Jose R and Leite, Julia and Santana, Pedro H and Oliveira, Pedro P and Rodrigues, Riei and Teobaldo, Tamara and Dutra, Vinıcius and Araujo, Victor and Barros, Edna},
}

@article{fujita_robodragons_nodate,
	title = {{RoboDragons} 2024 {Extended} {Team} {Description}},
	abstract = {RoboDragons are a team of the RoboCupSoccer Small Size League from Aichi Prefectural University, Japan. This paper shares two technical topics with respect to our system updates between 2023 and 2024: one is brief introduction of our new robots and another is experimental evaluation of a depth estimator based on on-board camera images.},
	language = {en},
	author = {Fujita, Shosei and Ito, Masahide},
}

@article{leme_robofei_nodate,
	title = {{RoboFEI} 2024 {Team} {Description} {Paper}},
	abstract = {This paper presents the current state of the RoboFEI Small Size League team as it stands for RoboCup International Small Size League competition 2024, in Eindhoven, Netherlands. The paper contains descriptions of mechanical design, studies made about chip kick efficiency, path tracking, obstacle avoidance and path planning.},
	language = {en},
	author = {Leme, Alexandre A and Neto, Alvaro D and Simomura, Danilo Y},
}

@article{barreto_roboime_nodate,
	title = {{RoboIME}: {Igniting} {Innovation}, {Shaping} the {Future} in {RoboCup} 2024},
	abstract = {This paper describes the electronic, mechanical, and software designs developed by the RoboIME Team to join the RoboCup 2024. The overall concepts are in agreement with the rules of Small Size League 2024. This is the tenth time RoboIME participates in the RoboCup tournament.},
	language = {en},
	author = {Barreto, Henrique and Horie, Lucio E and Frese, Enzo G and de Freitas and Antunes, Marcos C and Baldi, Eduardo and Melo, Ebert H V},
}

@article{nayak_robojackets_nodate,
	title = {{RoboJackets} 2024 {Team} {Description} {Paper}},
	abstract = {This paper describes the improvements implemented by the Georgia Institute of Technology’s RoboCup SSL team, RoboJackets, in preparation to compete in RoboCup 2024 in Eindhoven, Netherlands. Mechanical modifications attempted to improve the control and motion profile. A firmware rewrite and a control board redesign were established in an effort to modernize a standard embedded system. Our software changes resulted in a refined strategy that built on the agent-based principle. As always, all of our designs and code are open-sourced. See the RoboCup SSL website for links, or search for “RoboCup” on our GitHub page.},
	language = {en},
	author = {Nayak, Prabhanjan and Das, Mili and Parikh, Sid and Wert, Nathaniel and Hau, Kelvin and Kota, Saihari},
}

@article{chen_src_nodate,
	title = {{SRC} {Extended} {Team} {Description} {Paper} for {RoboCup} 2024},
	abstract = {This paper introduces the achievements which the SRC Team made in the last year. In the software part, we achieve adaptive supporting point calculation, ball prediction and simulation of visual blind zones. In the electronics part, an automatic motion calibration method is introduced. In the mechanics part, we imporve the center of gravity and the roller. We hope to do well in RoboCup 2024 based on these achievements.},
	language = {en},
	author = {Chen, Ziming and Pan, Shaoming and Wang, Yuquan and Jiang, Liangcheng and Peng, Juntong and Tan, Yuhong and Zhu, Xiaoxiao},
}

@article{arriagada_sysmic_nodate,
	title = {Sysmic {Robotics} {Team} {Description} {Paper} 2024},
	abstract = {This paper briefly describes what the team has developed for the fourth generation of robots, in particular by mentioning the changes that have been made since the last participation at the 2023 RoboCup in Bourdeaux, France. The team’s approach this year was to optimize the kicker system, restructure the design of the robot’s prototype, integrate a new ball proximity sensor, the creation of a new client and finally, a new version of the data package sent to each robot. The topics involving the work, such as electrical, mechanics, software and firmware, were designed according to satisfy the Robocup rules.},
	language = {en},
	author = {Arriagada, Aaron and Cortes, Nelson and Jimenez, Ignacio and Marihuan, Gerson and Richards, Irina and Tapia, Claudio and Valenzuela, Cristobal},
}

@article{avidano_-team_nodate,
	title = {The {A}-{Team} {Team} {Description} {Paper} 2024},
	abstract = {The A-Team” is a community team from the United States participating in our second year of RoboCup SSL. Our mission is to practice technical skills, inspire the communities in which we are present, and stay connected with friends across the globe. This paper presents the work done since the 2023 TDP. Focus is placed on the development of our first competition-ready platform, ongoing improvements to platform and software since the 2023 Bordeaux event, and exploratory work experimenting with novel approaches to SSL challenges.},
	language = {en},
	author = {Avidano, C and Barulic, M and Clark, C and Osawa, R},
}

@article{veeraghanta_2024_nodate,
	title = {2024 {Team} {Description} {Paper}: {The} {Bots}},
	abstract = {This paper details the design and development of the systems of The Bots, a Small Size League team intending to compete in RoboCup 2024 in Eindhoven, Netherlands. We introduce a unibody drivetrain frame, new sub-wheel designs for our omni-wheels, flexure based dribbler damping, "power pillars" to improve cable management between PCBs, a quick release battery cage, smarter capacitor discharging, improved motor drivers, an optimized pass evaluator, and software based automatic robot ID assignment.},
	language = {en},
	author = {Veeraghanta, Akhil and Bryant, Henry and Zheng, Simon and MacDougall, Mathew and Guido, Steven and Bontkes, Liam},
}

@article{kadekar_tritonsrcsc_nodate,
	title = {{TritonsRCSC} 2024 {Team} {Description} {Paper}},
	abstract = {This paper describes the development of our overall robot design, including developments over the past year, and the assembly of functional autonomous robots aiming to compete in the 2024 RoboCup Small Size League tournament in Eindhoven, the Netherlands. Compared to last year’s theoretical design with only the drive train actualized for practice, this year’s development added more capabilities to our robots. These include, but are not limited to, improvements to obstacle avoidance algorithm, controlled omni-directional movement and PID tuning, shooting decision-making and directional kicking, coordinated passing between two actors, and dribbling while in motion. We took an approach that prioritized mastering basic functionality and largely ignored complex maneuvers and skills.},
	language = {en},
	author = {Kadekar, Rohil and Zarif, Mohammad Mustahsin and Ramshankar, Akhil and Charry, Matthew and Wu, Allen and Ji, Nick and Tai, Terri},
}

@article{abousaleh_2024_nodate,
	title = {2024 {Team} {Description} {Paper}: {UBC} {Thunderbots}},
	abstract = {This TDP details design improvements and innovations UBC Thunderbots has made in preparation for RoboCup 2024 in Eindhoven, Netherlands. The team’s primary goal was to investigate and resolve issues surrounding trajectory control and ball placement in the newest generation of robots used at RoboCup 2023. The secondary goal was to innovate on previous systems in these robots for design efficiency and usability. We additionally describe the wide-ranging software architecture improvements to robot software, motion planning, strategy and planning, simulation, and visualization that were implemented since RoboCup 2021.},
	language = {en},
	author = {Abousaleh, Ahmad and Balamurali, Arun and Blair, Ben and Cao, Rocky and Charara, Musa and Chee, Lauren and Coffin, James and Guo, Jeanette and Ha, William and Haas, Florian and Kong, Tara and Khan, Raiaan and Lee, Clinton and Levy, Omri and Nedjabat, Ryan and Phung, Mark and Sidhu, Amtoj and Sturn, Dannon and Tong, Matthew and Vasilchikov, Boris and Wakaba, Kenny and Zareian, Nima and Banna, Saurav and Zhou, Paul and Zhou, Yichen Benjamin},
}

@article{godinho_description_nodate,
	title = {Description of the 2024 {Warthog} {Robotics} {SSL} {Project}},
	abstract = {This paper presents the Warthog Robotics Magic project and its main improvements made to this RoboCup SSL project during last year. During the last research and development cycle, changes were made to the goal keeper’s strategy, an automatic calibration to the Kalman filter was introduced and a log file for WRCoach was implemented.},
	language = {en},
	author = {Godinho, Caio O and Neumann, Eduarda F and Francoso, Pedro A P},
}

@article{zhao_zjunlict_nodate,
	title = {{ZJUNlict} {Extended} {Team} {Description} {Paper}},
	abstract = {This paper mainly describes the work of the ZJUNlict team in the past year in both hardware and software. In the hardware part, new control and communication architectures were designed based on v2023 robot [1]. In the software part, decision module was reorganized in a modular way, and attacking and defending strategies were modified to adapt to the high-tempo games, including a brand new defence system. A standard benchmark was also proposed for teams to evaluate the capabilities of their robots in an objective way.},
	language = {en},
	author = {Zhao, Anke and Yu, Pengfei and Huang, Zheyuan and Shen, Ning and Yang, Jialei and Yu, Jiazheng and Chen, Zhike and Wang, Liang and Xiong, Rong},
}

@misc{noauthor_2024_2024,
	title = {2024 {Team} {Description} {Paper}: {UBC} {Thunderbots}},
	shorttitle = {2024 {Team} {Description} {Paper}},
	url = {https://tdpsearch.com/#/tdp/soccer_smallsize__2024__UBC_Thunderbots__0?ref=list},
	language = {English},
	publisher = {UBC Thunderbots},
	year = {2024},
}

@article{noauthor_notitle_nodate-3,
}

@article{al_mamun_embedded_2018,
	title = {Embedded {System} for {Motion} {Control} of an {Omnidirectional} {Mobile} {Robot}},
	volume = {6},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/OAPA.html},
	issn = {2169-3536},
	url = {http://ieeexplore.ieee.org/document/8262666/},
	doi = {10.1109/ACCESS.2018.2794441},
	urldate = {2024-09-09},
	journal = {IEEE Access},
	author = {Al Mamun, Md. Abdullah and Nasir, Mohammad Tariq and Khayyat, Ahmad},
	year = {2018},
	pages = {6722--6739},
}

@incollection{siciliano_wheeled_2016,
	address = {Cham},
	title = {Wheeled {Robots}},
	isbn = {9783319325507 9783319325521},
	url = {https://link.springer.com/10.1007/978-3-319-32552-1_24},
	language = {en},
	urldate = {2024-09-09},
	booktitle = {Springer {Handbook} of {Robotics}},
	publisher = {Springer International Publishing},
	author = {Chung, Woojin and Iagnemma, Karl},
	editor = {Siciliano, Bruno and Khatib, Oussama},
	year = {2016},
	doi = {10.1007/978-3-319-32552-1_24},
	pages = {575--594},
}

@inproceedings{araujo_dribbler_2020,
	address = {Natal, Brazil},
	title = {Dribbler and {Kicker} {Systems} to {Small} {Size} {Soccer} {League} {Robots}: {A} {Study} and {Project} to {Latin} {American} {Robotics} {Competition}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {9780738111537},
	shorttitle = {Dribbler and {Kicker} {Systems} to {Small} {Size} {Soccer} {League} {Robots}},
	url = {https://ieeexplore.ieee.org/document/9306957/},
	doi = {10.1109/LARS/SBR/WRE51543.2020.9306957},
	urldate = {2024-09-06},
	booktitle = {2020 {Latin} {American} {Robotics} {Symposium} ({LARS}), 2020 {Brazilian} {Symposium} on {Robotics} ({SBR}) and 2020 {Workshop} on {Robotics} in {Education} ({WRE})},
	publisher = {IEEE},
	author = {Araujo, Joaquim E. A. and De Lima, Marcos E. A. and Montarroyos, Caio M. A. and Arruda, Luiz H. S. and Silva, Pedro J. L. and Pinto, Adam H. M. and Souza, Julia D. T. and Cajueiro, Joao P. C.},
	month = nov,
	year = {2020},
	pages = {1--6},
}

@article{ommer_extended_nodate,
	title = {Extended {Team} {Description} for {RoboCup} 2024},
	abstract = {This paper presents latest improvements of ball control and path planning algorithms of TIGERs Mannheim, a Small Size League (SSL) team intending to participate in RoboCup 2024 in Eindhoven, Netherlands. This year, the ETDP will focus on state-of-the-art methods for dribbling a ball and the employed control architecture. Furthermore, many implementation details and improvements to our trajectorysampling-based path planning are depicted. This includes generating and executing trajectories, handling dynamic obstacles, and dealing with corner cases.},
	language = {en},
	author = {Ommer, Nicolai and Ryll, André and Ratzel, Michael and Geiger, Mark},
}

@article{trinh_turtlerabbit_2024,
	title = {{TurtleRabbit} 2024 {SSL} {Team} {Description} {Paper}},
	abstract = {TurtleRabbit is a new RoboCup SSL team from Western Sydney University. This team description paper presents our approach in navigating some of the challenges in developing a new SSL team from scratch. SSL is dominated by teams with extensive experience and customised equipment that has been developed over many years. Here, we outline our approach in overcoming some of the complexities associated with replicating advanced open-sourced designs and managing the high costs of custom components. Opting for simplicity and cost-e↵ectiveness, our strategy primarily employs o↵-the-shelf electronics components and “hobby” brushless direct current (BLDC) motors, complemented by 3D printing and CNC milling. This approach helped us to streamline the development process and, with our open-sourced hardware design, hopefully will also lower the bar for other teams to enter RoboCup SSL in the future. The paper details the speciﬁc hardware choices, their approximate costs, the integration of electronics and mechanics, and the initial steps taken in software development, for our entry into SSL that aims to be simple yet competitive.},
	language = {en},
	author = {Trinh, Linh and Anzuman, Alif and Batkhuu, Eric and Chan, Dychen and Graf, Lisa and Jamal, Tharunimm and Namgyal, Jigme and Ng, Jason and Tsang, Wing Lam and Wang, X Rosalind and Yilmaz, Eren},
	year = {2024},
}

@article{yoshimoto_op-amp_nodate,
	title = {{OP}-{AmP} 2019 {Extended} {Team} {Discription} {Paper}},
	abstract = {This paper introduces explanations of hardware, circuit, and software of a RoboCup small size league team ”OP-AmP”. The most characteristic point in our team is that our robots can kick a curve shoot by using a multi-angle kicking device and high-speed dribbling device. The skill enables the robots to perform more ﬂexible in games than other teams.},
	language = {en},
	author = {Yoshimoto, Takamichi and Horii, Takato and Mizutani, Shoma and Iwauchi, Yasuyuki and Zenji, Shota},
}
